{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lung Cancer Risk Analysis: Comprehensive Python Notebook\n",
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report)\n",
    "from xgboost import XGBClassifier\n",
    "from pycaret.classification import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the Dataset\n",
    "df = pd.read_csv('/kaggle/input/lung-cancer-risk-dataset/lung_cancer_risk.csv')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "print(\"\\nColumn Names and Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle Missing Values\n",
    "# Create a copy for preprocessing\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Numeric columns: impute with median\n",
    "num_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in num_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "\n",
    "# Categorical columns: impute with mode\n",
    "cat_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in cat_cols:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "\n",
    "print(\"Missing values after treatment:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Data Visualization\n",
    "# Target distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_counts = df_clean['lung_cancer'].value_counts()\n",
    "plt.pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Distribution of Lung Cancer Cases')\n",
    "plt.show()\n",
    "\n",
    "# Interactive histograms with Altair\n",
    "alt.Chart(df_clean).mark_bar().encode(\n",
    "    alt.X('age:Q', bin=True),\n",
    "    alt.Y('count()'),\n",
    "    color='lung_cancer:N'\n",
    ").properties(width=300, height=200, title='Age Distribution by Lung Cancer Status').interactive()\n",
    "\n",
    "# Boxplots grouped by cancer status\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='lung_cancer', y='age', data=df_clean)\n",
    "plt.title('Age Distribution by Lung Cancer Status')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_df = df_clean.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "# Crosstab: Gender vs Lung Cancer\n",
    "gender_cancer = pd.crosstab(df_clean['gender'], df_clean['lung_cancer'], margins=True)\n",
    "print(\"Gender vs Lung Cancer Crosstab:\")\n",
    "print(gender_cancer)\n",
    "\n",
    "# Smoking status vs Lung Cancer\n",
    "smoking_cancer = pd.crosstab(df_clean['smoking'], df_clean['lung_cancer'], normalize='index') * 100\n",
    "print(\"\\nSmoking Status vs Lung Cancer (%):\")\n",
    "print(smoking_cancer)\n",
    "\n",
    "# Statistical patterns\n",
    "print(\"\\nAverage age by lung cancer status:\")\n",
    "print(df_clean.groupby('lung_cancer')['age'].mean())\n",
    "\n",
    "print(\"\\nAverage pack years by lung cancer status:\")\n",
    "print(df_clean.groupby('lung_cancer')['pack_years'].mean())\n",
    "\n",
    "# Feature Engineering\n",
    "# Create age groups\n",
    "df_clean['age_group'] = pd.cut(df_clean['age'], bins=[0, 40, 60, 80, 100], \n",
    "                               labels=['<40', '40-60', '60-80', '80+'])\n",
    "\n",
    "# Create heavy smoker flag\n",
    "df_clean['heavy_smoker'] = np.where(df_clean['pack_years'] > 20, 1, 0)\n",
    "\n",
    "# Create family risk flag\n",
    "df_clean['family_risk'] = np.where(df_clean['family_history'] == 'Yes', 1, 0)\n",
    "\n",
    "# Calculate risk score (example formula)\n",
    "df_clean['risk_score'] = (df_clean['age'] / 10) + (df_clean['pack_years'] / 10) + \\\n",
    "                         (df_clean['family_risk'] * 5)\n",
    "\n",
    "print(\"New features sample:\")\n",
    "display(df_clean[['age_group', 'heavy_smoker', 'family_risk', 'risk_score']].head())\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = df_clean.drop('lung_cancer', axis=1)\n",
    "y = df_clean['lung_cancer']\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "\n",
    "# Model Training with PyCaret\n",
    "pycaret_setup = setup(data=df_clean, target='lung_cancer', session_id=42,\n",
    "                      normalize=True, transformation=True, ignore_low_variance=True,\n",
    "                      remove_multicollinearity=True, multicollinearity_threshold=0.9)\n",
    "\n",
    "# Compare models\n",
    "best_model = compare_models(sort='AUC', n_select=3)\n",
    "print(\"Top 3 models based on AUC:\")\n",
    "print(best_model)\n",
    "\n",
    "# Create and tune the best model\n",
    "tuned_best_model = tune_model(best_model[0], optimize='AUC')\n",
    "final_model = finalize_model(tuned_best_model)\n",
    "\n",
    "# Manual XGBoost Training\n",
    "# Preprocess the data for manual model training\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, \n",
    "                          max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "y_pred_prob_xgb = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"XGBoost Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_pred_prob_xgb):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_xgb, average='weighted'):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_xgb, average='weighted'):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_xgb, average='weighted'):.4f}\")\n",
    "\n",
    "# Cross-validation for multiple models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', model)])\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='roc_auc')\n",
    "    cv_results[name] = scores.mean()\n",
    "    print(f\"{name} AUC: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "# Predictive Analysis and Risk Stratification\n",
    "# Generate probability scores\n",
    "proba_scores = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Define risk thresholds\n",
    "df_test = X_test.copy()\n",
    "df_test['true_label'] = y_test\n",
    "df_test['predicted_prob'] = proba_scores\n",
    "df_test['risk_category'] = pd.cut(proba_scores, \n",
    "                                  bins=[0, 0.3, 0.7, 1],\n",
    "                                  labels=['Low Risk', 'Medium Risk', 'High Risk'])\n",
    "\n",
    "print(\"Risk Category Distribution:\")\n",
    "print(df_test['risk_category'].value_counts())\n",
    "\n",
    "# Visualize risk distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df_test, x='predicted_prob', hue='risk_category', \n",
    "             element='step', stat='density')\n",
    "plt.title('Distribution of Predicted Risk Scores')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.show()\n",
    "\n",
    "# Show high-risk cases\n",
    "high_risk_cases = df_test[df_test['risk_category'] == 'High Risk']\n",
    "print(f\"Number of high-risk cases: {len(high_risk_cases)}\")\n",
    "print(\"High-risk cases characteristics:\")\n",
    "print(high_risk_cases[['age', 'pack_years', 'smoking', 'family_history', \n",
    "                       'predicted_prob']].head())\n",
    "\n",
    "# Model Comparison Summary\n",
    "# Compare PyCaret best model with manual XGBoost\n",
    "print(\"Model Comparison Summary:\")\n",
    "print(\"PyCaret Best Model:\", type(final_model).__name__)\n",
    "print(\"Manual XGBoost Model: XGBClassifier\")\n",
    "\n",
    "# Evaluate PyCaret model\n",
    "pycaret_predictions = predict_model(final_model, data=X_test)\n",
    "pycaret_accuracy = accuracy_score(y_test, pycaret_predictions['prediction_label'])\n",
    "pycaret_auc = roc_auc_score(y_test, pycaret_predictions['prediction_score'])\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['PyCaret Best', 'Manual XGBoost'],\n",
    "    'Accuracy': [pycaret_accuracy, accuracy_score(y_test, y_pred_xgb)],\n",
    "    'AUC': [pycaret_auc, roc_auc_score(y_test, y_pred_prob_xgb)],\n",
    "    'Precision': [precision_score(y_test, pycaret_predictions['prediction_label'], \n",
    "                                  average='weighted'),\n",
    "                  precision_score(y_test, y_pred_xgb, average='weighted')],\n",
    "    'Recall': [recall_score(y_test, pycaret_predictions['prediction_label'], \n",
    "                            average='weighted'),\n",
    "               recall_score(y_test, y_pred_xgb, average='weighted')],\n",
    "    'F1-Score': [f1_score(y_test, pycaret_predictions['prediction_label'], \n",
    "                          average='weighted'),\n",
    "                 f1_score(y_test, y_pred_xgb, average='weighted')]\n",
    "})\n",
    "\n",
    "display(metrics_df)\n",
    "\n",
    "# Key Influencing Features\n",
    "# Feature importance from XGBoost\n",
    "feature_names = (numeric_features + \n",
    "                 list(preprocessor.named_transformers_['cat']\n",
    "                 .named_steps['onehot'].get_feature_names_out(categorical_features)))\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances)\n",
    "plt.title('Top 10 Feature Importances from XGBoost Model')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary and Conclusion\n",
    "print(\"SUMMARY AND KEY FINDINGS\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. Best Performing Model:\", type(final_model).__name__)\n",
    "print(\"2. Key Influencing Features:\")\n",
    "print(\"   - Age (positive correlation with cancer risk)\")\n",
    "print(\"   - Pack Years (smoking intensity)\")\n",
    "print(\"   - Family History of Lung Cancer\")\n",
    "print(\"   - Asbestos Exposure\")\n",
    "print(\"3. Dataset Limitations:\")\n",
    "print(\"   - Class imbalance (may need stratification or sampling)\")\n",
    "print(\"   - Potential missing data in key variables\")\n",
    "print(\"   - Self-reported data may have accuracy issues\")\n",
    "\n",
    "print(\"\\nNEXT STEPS\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. External validation on new dataset\")\n",
    "print(\"2. Model explainability using SHAP values\")\n",
    "print(\"3. Deployment as web application or API\")\n",
    "print(\"4. Continuous monitoring and retraining protocol\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
