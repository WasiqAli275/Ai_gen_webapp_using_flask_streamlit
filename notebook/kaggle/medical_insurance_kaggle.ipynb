{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b635ef",
   "metadata": {},
   "source": [
    "# Medical Insurance Cost Prediction\n",
    "\n",
    "**Dataset:** https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset/data  \n",
    "**Goal:** Predict medical insurance charges (costs) using patient demographic and health information. This notebook is built to run on Kaggle's default environment without installing additional packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d5698",
   "metadata": {},
   "source": [
    "## 1 — Imports and Version Check\n",
    "\n",
    "We import the commonly available libraries on Kaggle and print their versions so you can confirm compatibility with the Kaggle runtime. No `pip install` commands are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "\n",
    "# optional xgboost import — available on Kaggle in most runtimes; handle gracefully if absent\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    _XGBOOST_AVAILABLE = True\n",
    "except Exception:\n",
    "    _XGBOOST_AVAILABLE = False\n",
    "\n",
    "print('Python:', sys.version.splitlines()[0])\n",
    "print('numpy :', np.__version__)\n",
    "print('pandas :', pd.__version__)\n",
    "print('matplotlib :', plt.__version__)\n",
    "print('seaborn :', sns.__version__)\n",
    "print('scikit-learn :', sklearn.__version__)\n",
    "print('tensorflow :', tf.__version__)\n",
    "print('plotly :', px.__version__)\n",
    "print('xgboost available :', _XGBOOST_AVAILABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283fe5c5",
   "metadata": {},
   "source": [
    "## 2 — Load Dataset\n",
    "\n",
    "We load the CSV from the Kaggle input path. If the Kaggle input is not present (for local runs), the cell will try to load `./insurance.csv` if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33629ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_path = '/kaggle/input/medical-insurance-cost-dataset/insurance.csv'\n",
    "local_path = './insurance.csv'\n",
    "\n",
    "if os.path.exists(kaggle_path):\n",
    "    data_path = kaggle_path\n",
    "elif os.path.exists(local_path):\n",
    "    data_path = local_path\n",
    "else:\n",
    "    data_path = None\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError('Could not find insurance.csv at the Kaggle input path or local path. On Kaggle make sure the dataset is added to the notebook.\n",
    "')\n",
    "\n",
    "print('Loading dataset from:', data_path)\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print('\n",
    "Shape:', df.shape)\n",
    "display(df.head())\n",
    "print('\n",
    "Info:')\n",
    "display(df.info())\n",
    "print('\n",
    "Summary statistics:')\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff3c3f",
   "metadata": {},
   "source": [
    "## 3 — Data Cleaning & Feature Engineering\n",
    "\n",
    "We check for missing values, treat outliers where appropriate, and encode categorical variables. We also add engineered features such as BMI categories and smoker interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing = df.isnull().sum()\n",
    "print('Missing values per column:\n",
    "', missing)\n",
    "\n",
    "# Make a copy for processing and show initial distribution of 'charges'\n",
    "df_proc = df.copy()\n",
    "print('\n",
    "Charges distribution (summary):')\n",
    "display(df_proc['charges'].describe())\n",
    "\n",
    "# Visual check for outliers in charges\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x=df_proc['charges'])\n",
    "plt.title('Boxplot of charges (original)')\n",
    "plt.show()\n",
    "\n",
    "# Create a log-transformed target to reduce skewness (we keep original target for interpretation)\n",
    "df_proc['log_charges'] = np.log1p(df_proc['charges'])\n",
    "print('\n",
    "Log-transformed charges summary:')\n",
    "display(df_proc['log_charges'].describe())\n",
    "\n",
    "# Create BMI categories\n",
    "def bmi_category(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'underweight'\n",
    "    elif bmi < 25:\n",
    "        return 'normal'\n",
    "    elif bmi < 30:\n",
    "        return 'overweight'\n",
    "    else:\n",
    "        return 'obese'\n",
    "\n",
    "df_proc['bmi_cat'] = df_proc['bmi'].apply(bmi_category)\n",
    "\n",
    "# Binary encoding for 'sex' and 'smoker' (male:1, female:0; smoker:1, no:0)\n",
    "df_proc['sex_male'] = (df_proc['sex'] == 'male').astype(int)\n",
    "df_proc['smoker_flag'] = (df_proc['smoker'] == 'yes').astype(int)\n",
    "\n",
    "# One-hot encode 'region' using get_dummies for transparency now (we will also show pipeline-based encoding later)\n",
    "df_region = pd.get_dummies(df_proc['region'], prefix='region')\n",
    "df_proc = pd.concat([df_proc, df_region], axis=1)\n",
    "\n",
    "# Smoker interaction features\n",
    "df_proc['smoker_bmi'] = df_proc['smoker_flag'] * df_proc['bmi']\n",
    "df_proc['smoker_age'] = df_proc['smoker_flag'] * df_proc['age']\n",
    "\n",
    "print('After feature engineering — sample rows:')\n",
    "display(df_proc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc571a",
   "metadata": {},
   "source": [
    "### Before-and-after summaries\n",
    "We show how the number of columns changed and a quick view of the engineered values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original columns count:', len(df.columns))\n",
    "print('Processed columns count:', len(df_proc.columns))\n",
    "display(df_proc[['charges','log_charges','bmi','bmi_cat','sex_male','smoker_flag','smoker_bmi']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07271e78",
   "metadata": {},
   "source": [
    "## 4 — Exploratory Data Analysis (9 plots + 1 interactive)\n",
    "\n",
    "We present a grid of 9 static plots and one interactive Plotly visualization. Interpretations follow each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare numeric features for pairplot and correlation\n",
    "numeric_cols = ['age','bmi','children','charges']\n",
    "sns.set(style='whitegrid')\n",
    "fig, axes = plt.subplots(3,3, figsize=(16,12))\n",
    "\n",
    "# 1 Distribution of charges\n",
    "sns.histplot(df_proc['charges'], kde=True, ax=axes[0,0], color='tab:blue')\n",
    "axes[0,0].set_title('Distribution of Charges')\n",
    "\n",
    "# 2 Scatter: age vs charges\n",
    "sns.scatterplot(data=df_proc, x='age', y='charges', hue='smoker', ax=axes[0,1])\n",
    "axes[0,1].set_title('Age vs Charges (colored by smoker)')\n",
    "\n",
    "# 3 Scatter: bmi vs charges\n",
    "sns.scatterplot(data=df_proc, x='bmi', y='charges', hue='smoker', ax=axes[0,2])\n",
    "axes[0,2].set_title('BMI vs Charges')\n",
    "\n",
    "# 4 Boxplot: charges by smoker\n",
    "sns.boxplot(data=df_proc, x='smoker', y='charges', ax=axes[1,0])\n",
    "axes[1,0].set_title('Charges by Smoker')\n",
    "\n",
    "# 5 Barplot: mean charges by region\n",
    "region_means = df_proc.groupby('region')['charges'].mean().reset_index()\n",
    "sns.barplot(data=region_means, x='region', y='charges', ax=axes[1,1])\n",
    "axes[1,1].set_title('Mean Charges by Region')\n",
    "\n",
    "# 6 Pairplot for numeric features (use a small sample for speed)\n",
    "sample_for_pair = df_proc[numeric_cols].sample(min(500, len(df_proc)), random_state=1)\n",
    "sns.pairplot(sample_for_pair)\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "# 7 Correlation heatmap\n",
    "corr = df_proc[numeric_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', ax=axes[2,0])\n",
    "axes[2,0].set_title('Correlation Heatmap')\n",
    "\n",
    "# 8 Violin plot: children vs charges\n",
    "sns.violinplot(data=df_proc, x='children', y='charges', ax=axes[2,1])\n",
    "axes[2,1].set_title('Children vs Charges (violin)')\n",
    "\n",
    "# 9 Density plot of log_charges (helps with skew)\n",
    "sns.kdeplot(df_proc['log_charges'], ax=axes[2,2], fill=True, color='tab:green')\n",
    "axes[2,2].set_title('Density of log(1+charges)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interactive plot: Plotly scatter (age vs charges)\n",
    "fig_px = px.scatter(df_proc, x='age', y='charges', color='smoker', hover_data=['bmi','children','region'], title='Interactive: Age vs Charges (smoker)')\n",
    "fig_px.update_traces(marker=dict(size=6))\n",
    "fig_px.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24608b2e",
   "metadata": {},
   "source": [
    "**Interpretation (high level):**\n",
    "- `smoker` has a strong effect on `charges` - smokers pay much higher costs.\n",
    "- `age` and `bmi` positively correlate with charges but with substantial spread.\n",
    "- `children` shows smaller differences.\n",
    "- Log transform reduces skew in `charges` and can stabilize training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f966b",
   "metadata": {},
   "source": [
    "## 5 — Prepare Data for Modeling\n",
    "\n",
    "We create feature and target arrays, split into train/test, and construct a preprocessing pipeline using `ColumnTransformer`. The pipeline scales numeric features and one-hot encodes categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose features (use engineered ones and original meaningful columns)\n",
    "feature_cols = ['age', 'bmi', 'children', 'sex_male', 'smoker_flag', 'smoker_bmi', 'smoker_age', 'bmi_cat', 'region']\n",
    "target_col = 'charges'\n",
    "X = df_proc[feature_cols].copy()\n",
    "y = df_proc[target_col].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "# Preprocessing: numeric and categorical\n",
    "numeric_features = ['age','bmi','children','smoker_bmi','smoker_age']\n",
    "categorical_features = ['sex_male','smoker_flag','bmi_cat','region']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit preprocessor on training data and transform\n",
    "preprocessor.fit(X_train)\n",
    "X_train_trans = preprocessor.transform(X_train)\n",
    "X_test_trans = preprocessor.transform(X_test)\n",
    "\n",
    "print('Transformed train shape:', X_train_trans.shape)\n",
    "\n",
    "# Save preprocessor pipeline for later use\n",
    "preproc_path = '/kaggle/working/preprocessor_pipeline.joblib'\n",
    "joblib.dump(preprocessor, preproc_path)\n",
    "print('Preprocessor saved to:', preproc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96deae",
   "metadata": {},
   "source": [
    "## 6 — Build and Train TensorFlow Neural Network\n",
    "\n",
    "We train a simple feed-forward network with early stopping and monitor MAE. We'll evaluate using MAE, RMSE and R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "input_dim = X_train_trans.shape[1]\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model (use modest epochs so it runs quickly on Kaggle)\n",
    "history = model.fit(X_train_trans, y_train, validation_split=0.2, epochs=200, batch_size=32, callbacks=[early_stop], verbose=2)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = '/kaggle/working/tf_insurance_model'\n",
    "model.save(model_path)\n",
    "print('TensorFlow model saved to:', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c9d30",
   "metadata": {},
   "source": [
    "### Training Curves\n",
    "We plot training and validation loss and MAE to inspect for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "hist = history.history\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist['loss'], label='train_loss')\n",
    "plt.plot(hist['val_loss'], label='val_loss')\n",
    "plt.legend(); plt.title('Loss (MSE)')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist['mae'], label='train_mae')\n",
    "plt.plot(hist['val_mae'], label='val_mae')\n",
    "plt.legend(); plt.title('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c061b77",
   "metadata": {},
   "source": [
    "## 7 — Evaluation on Test Set\n",
    "We compute MAE, RMSE and R² on the test set and provide prediction plots and residual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e93fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test_trans).reshape(-1)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'TF Model — MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}')\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Charges')\n",
    "plt.ylabel('Predicted Charges')\n",
    "plt.title('Predicted vs Actual — TensorFlow')\n",
    "plt.show()\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.title('Residuals Distribution')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(y_pred, residuals, alpha=0.6)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45484588",
   "metadata": {},
   "source": [
    "## 8 — Optional: XGBoost Benchmark\n",
    "We train a simple XGBoost regressor for comparison if `xgboost` is available in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _XGBOOST_AVAILABLE:\n",
    "    print('Training XGBoost regressor (this may take a short while)...')\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.05, random_state=42, n_jobs=4)\n",
    "    xgb_model.fit(X_train_trans, y_train, eval_set=[(X_test_trans, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "    y_pred_xgb = xgb_model.predict(X_test_trans)\n",
    "    mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "    rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
    "    r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "    print(f'XGBoost — MAE: {mae_xgb:.2f}, RMSE: {rmse_xgb:.2f}, R2: {r2_xgb:.4f}')\n",
    "    # Feature importances — map back to column names where possible\n",
    "    try:\n",
    "        # Recover feature names from the preprocessor\n",
    "        ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_cols = categorical_features[:2] + list(ohe.get_feature_names_out(categorical_features[2:]))\n",
    "        num_cols = numeric_features\n",
    "        feature_names = num_cols + list(cat_cols)\n",
    "    except Exception:\n",
    "        # Fallback to numeric-length placeholders\n",
    "        feature_names = [f'f{i}' for i in range(X_train_trans.shape[1])]\n",
    "    importances = xgb_model.feature_importances_\n",
    "    top_idx = np.argsort(importances)[-10:][::-1]\n",
    "    print('Top XGBoost features:')\n",
    "    for i in top_idx:\n",
    "        name = feature_names[i] if i < len(feature_names) else f'feat_{i}'\n",
    "        print(f'  {name}: {importances[i]:.4f}')\n",
    "else:\n",
    "    print('XGBoost is not available in this environment. Skipping XGBoost benchmark.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e70f8",
   "metadata": {},
   "source": [
    "## 9 — Save Models & Pipeline Paths\n",
    "We already saved the TensorFlow model and the preprocessing pipeline earlier; display their locations again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preprocessor pipeline:', preproc_path)\n",
    "print('TensorFlow model folder:', model_path)\n",
    "# Optionally save a lightweight sklearn wrapper or the model weights (already saved above)\n",
    "# joblib.dump(model, '/kaggle/working/tf_model_sklearn_wrapper.joblib')  # not recommended for TF models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68348fa",
   "metadata": {},
   "source": [
    "## 10 — Summary & Next Steps\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
