{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Jupyter Notebook file named 'mnist_analysis.ipynb'\n",
    "# Copy and paste the following content into the file\n",
    "\n",
    "# %% [markdown]\n",
    "# # MNIST Handwritten Digit Recognition\n",
    "# \n",
    "# This notebook analyzes the MNIST dataset of handwritten digits using machine learning techniques.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Importing Libraries\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Loading and Exploring the Data\n",
    "\n",
    "# %%\n",
    "# Load the dataset\n",
    "df = pd.read_csv('mnist.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()\n",
    "\n",
    "# %%\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum().sum())  # Should be 0 for this dataset\n",
    "\n",
    "# %%\n",
    "# Check the distribution of labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Distribution of Digits in the Dataset')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Data Preprocessing\n",
    "\n",
    "# %%\n",
    "# Separate features and labels\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Normalize the pixel values (0-255 -> 0-1)\n",
    "X = X / 255.0\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Visualizing the Digits\n",
    "\n",
    "# %%\n",
    "# Function to display digits\n",
    "def plot_digits(images, labels, n_rows=2, n_cols=5):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n_rows * n_cols):\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Label: {labels.iloc[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display some examples from the training set\n",
    "plot_digits(X_train.values, y_train)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Dimensionality Reduction with PCA\n",
    "\n",
    "# %%\n",
    "# Apply PCA to reduce dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Plot the first two principal components\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap='tab10', alpha=0.6)\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('PCA of MNIST Dataset')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Model Training - Random Forest\n",
    "\n",
    "# %%\n",
    "# Train a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Model Training - Neural Network\n",
    "\n",
    "# %%\n",
    "# Build a simple neural network\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=15, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=1)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Model Evaluation\n",
    "\n",
    "# %%\n",
    "# Evaluate the neural network\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Neural Network Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Make predictions with the neural network\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn_classes = np.argmax(y_pred_nn, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_nn_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn_classes))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Visualizing Misclassified Examples\n",
    "\n",
    "# %%\n",
    "# Find misclassified examples\n",
    "misclassified_idx = np.where(y_pred_nn_classes != y_test)[0]\n",
    "\n",
    "# Display some misclassified examples\n",
    "if len(misclassified_idx) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, idx in enumerate(misclassified_idx[:10]):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(X_test.iloc[idx].values.reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'True: {y_test.iloc[idx]}, Pred: {y_pred_nn_classes[idx]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No misclassified examples found!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Conclusion\n",
    "\n",
    "# %%\n",
    "# Compare model performances\n",
    "models = ['Random Forest', 'Neural Network']\n",
    "accuracies = [accuracy_rf, test_acc]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(models, accuracies, color=['skyblue', 'lightgreen'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "print(\"Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
